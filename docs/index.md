# Godot RL Agents - Documentation Index

> A Deep Reinforcement Learning package for the Godot game engine

## Project Overview

| Property | Value |
|----------|-------|
| **Type** | Monolith (single cohesive codebase) |
| **Project Type** | Python Library |
| **Primary Language** | Python 3.8+ |
| **Architecture** | Wrapper/Adapter Pattern |

## Quick Reference

| Component | Details |
|-----------|---------|
| **Tech Stack** | Python, PyTorch, StableBaselines3, Gymnasium |
| **Entry Point** | `gdrl` CLI, `from godot_rl.core.godot_env import GodotEnv` |
| **Architecture Pattern** | Layered with Adapter Pattern |

## Generated Documentation

Core project documentation generated by the document-project workflow:

- [Project Overview](./project-overview.md) - Executive summary and quick start
- [Architecture](./architecture.md) - System architecture and design decisions
- [Source Tree Analysis](./source-tree-analysis.md) - Annotated directory structure
- [Development Guide](./development-guide.md) - Setup, testing, and contribution

## Existing Documentation

Original documentation maintained by the project:

### Tutorials

- [Custom Environment Tutorial](./CUSTOM_ENV.md) - Create your own Godot RL environments
- [Imitation Learning](./IMITATION_LEARNING.md) - Learn from demonstrations

### Framework Guides

- [StableBaselines3 Advanced](./ADV_STABLE_BASELINES_3.md) - SB3 deep dive
- [CleanRL Advanced](./ADV_CLEAN_RL.md) - CleanRL integration guide
- [Ray RLLib Advanced](./ADV_RLLIB.md) - RLLib configuration and usage
- [Sample Factory Advanced](./ADV_SAMPLE_FACTORY.md) - High-throughput training

### Reference

- [Example Environments](./EXAMPLE_ENVIRONMENTS.md) - Available training environments
- [Node Reference](./NODE_REFERENCE.md) - Godot plugin node documentation
- [Training Statistics](./TRAINING_STATISTICS.md) - Monitoring training progress
- [Training Multiple Policies](./TRAINING_MULTIPLE_POLICIES.md) - Multi-policy setups

### Guides

- [General Tips](./GENERAL_TIPS.md) - Best practices and recommendations
- [Working with C#](./WORKING_WITH_CSHARP.md) - C# integration for ONNX inference
- [Troubleshooting](./TROUBLESHOOTING.md) - Common issues and solutions

### Planning

- [Roadmap](./ROADMAP.md) - Future development plans

## Getting Started

### 1. Install the Library

```bash
pip install godot-rl
```

### 2. Download an Example Environment

```bash
gdrl.env_from_hub -r edbeeching/godot_rl_JumperHard
chmod +x examples/godot_rl_JumperHard/bin/JumperHard.x86_64  # Linux only
```

### 3. Train an Agent

```bash
python examples/stable_baselines3_example.py \
  --env_path=examples/godot_rl_JumperHard/bin/JumperHard.x86_64 \
  --experiment_name=Experiment_01 \
  --viz
```

### 4. Create Your Own Environment

Follow the [Custom Environment Tutorial](./CUSTOM_ENV.md).

## External Resources

- [GitHub Repository](https://github.com/edbeeching/godot_rl_agents)
- [Discord Community](https://discord.gg/HMMD2J8SxY)
- [AAAI-2022 Paper](https://arxiv.org/abs/2112.03636)
- [Video Tutorial](https://www.youtube.com/watch?v=f8arMv_rtUU)
- [Example Environments Repository](https://github.com/edbeeching/godot_rl_agents_examples)
- [Godot Plugin Repository](https://github.com/edbeeching/godot_rl_agents_plugin)

---

*Documentation generated: 2026-01-13*
*Workflow: document-project v1.2.0*
*Scan Level: Quick Scan*
